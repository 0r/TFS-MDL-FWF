"""
    Multivariate Wald-Wolfowitz test for two samples in separate CSV files.
    See:
      Friedman, Jerome H., and Lawrence C. Rafsky.
      "Multivariate generalizations of the Wald-Wolfowitz and Smirnov two-sample tests."
      The Annals of Statistics (1979): 697-717.
    Given multivariate sample X of length m and sample Y of length n, test the null hypothesis:
        H_0: The samples were generated by the same distribution
    The algorithm uses a KD-tree to construct the minimum spanning tree, therefore is O(Nk log(Nk))
    instead of O(N^3), where N = m + n is the total number of observations. Though approximate,
    results are generally valid. See also:
    Monaco, John V.
    "Classification and authentication of one-dimensional behavioral biometrics."
    Biometrics (IJCB), 2014 IEEE International Joint Conference on. IEEE, 2014.
    The input files should be CSV files with no header and row observations, for example:
    X.csv
    -----
    1,2
    2,2
    3,1
    Y.csv
    -----
    1,1
    2,4
    3,2
    4,2
    Usage:
    $ python X.csv Y.csv
    > W = 0.485, 5 runs
    > p = 0.6862
    > Fail to reject H_0 at 0.05 significance level
    > The samples appear to have similar distribution
"""
import numpy as np
import pandas as pd
import scipy.stats as stats
from sklearn.neighbors import kneighbors_graph
from scipy.sparse.csgraph import minimum_spanning_tree
#'''
from sklearn.experimental import enable_iterative_imputer  # noqa
from sklearn.impute import IterativeImputer



def mst_edges(V, k):
    """
    Construct the approximate minimum spanning tree from vectors V
    :param: V: 2D array, sequence of vectors
    :param: k: int the number of neighbor to consider for each vector
    :return: V ndarray of edges forming the MST
    """

    # k = len(X)-1 gives the exact MST
    k = min(len(V) - 1, k)

    # generate a sparse graph using the k nearest neighbors of each point
    G = kneighbors_graph(V, n_neighbors=k, mode='distance')

    # Compute the minimum spanning tree of this graph
    full_tree = minimum_spanning_tree(G, overwrite=True)

    return np.array(full_tree.nonzero()).T


def ww_test(X, Y, k=10):
    """
    Multi-dimensional Wald-Wolfowitz test
    :param X: multivariate sample X as a numpy ndarray
    :param Y: multivariate sample Y as a numpy ndarray
    :param k: number of neighbors to consider for each vector
    :return: W the WW test statistic, R the number of runs
    """
    m, n = len(X), len(Y)
    N = m + n

    XY = np.concatenate([X, Y]).astype(np.float)

    # XY += np.random.normal(0, noise_scale, XY.shape)

    edges = mst_edges(XY, k)

    labels = np.array([0] * m + [1] * n)

    c = labels[edges]
    runs_edges = edges[c[:, 0] == c[:, 1]]

    # number of runs is the total number of observations minus edges within each run
    R = N - len(runs_edges)

    # expected value of R
    e_R = ((2.0 * m * n) / N) + 1

    # variance of R is _numer/_denom
    _numer = 2 * m * n * (2 * m * n - N)
    _denom = N ** 2 * (N - 1)

    # see Eq. 1 in Friedman 1979
    # W approaches a standard normal distribution
    W = (R - e_R) / np.sqrt(_numer/_denom)

    return W, R


if __name__ == '__main__':

    dataFolderPath_Main = 'C:\\Users\\119275\\Documents\\GithubProjects\\TFS-MaskedFuzzyDist\\Data\\uni_mcar\\'
    #datasetNameSet = ['2d-U-mean\\', "2d-1G-mean\\", '2d-1G-var\\', '2d-1G-cov\\', '2d-2G-mean\\', '2d-4G-mean\\']
    datasetNameSet = ['uni_mcar\\']
    SIGNIFICANCE = 0.05
    
    drift_delta_max = 0.15
    drift_delta_size = 10
    num_test_PerDriftDelta = 50
    drift_delta = np.arange(0, drift_delta_max, drift_delta_max/drift_delta_size)
    
    train_miss = np.loadtxt(dataFolderPath_Main + 'train_miss', delimiter=',')
    imp = IterativeImputer(max_iter=10, random_state=0)
    train_miss_impute = imp.fit_transform(train_miss)
    train_full = np.loadtxt(dataFolderPath_Main + 'train_full', delimiter=',')
    
    # result[1]: train_miss error
    # result[2]: train_full error
    result = np.zeros([drift_delta_size, 3])
    result[:, 0] = drift_delta
    delta_idx = 0
    for delta in drift_delta:
        
        for i in range(num_test_PerDriftDelta):
            print(delta, i)
            test_miss = np.loadtxt(('%stest_miss_%.2f_%d' %(dataFolderPath_Main, delta, i)), delimiter=',')
            test_miss_impute = imp.fit_transform(test_miss)
            test_full = np.loadtxt(('%stest_full_%.2f_%d' %(dataFolderPath_Main, delta, i)), delimiter=',')
            
            W_miss, R_miss = ww_test(train_miss_impute, test_miss_impute)
            pvalue_miss = stats.norm.cdf(W_miss)  # one sided test
            reject_miss = pvalue_miss <= SIGNIFICANCE
            if reject_miss:
                result[delta_idx, 1] = result[delta_idx, 1] + 1
            
            W_full, R_full = ww_test(train_full, test_full)
            pvalue_full = stats.norm.cdf(W_full)  # one sided test
            reject_full = pvalue_full <= SIGNIFICANCE
            if reject_full:
                result[delta_idx, 2] = result[delta_idx, 2] + 1
        delta_idx = delta_idx + 1
        
    print(result)
    
    
    
    
    
    
    
    
    
    
    
    
    